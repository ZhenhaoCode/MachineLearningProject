---
title: "Spotify"
date: "2022-12-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Analyse Music Influence amongst Southeast Asia Countries using Spotify Top Chart Data from 2017-2021 

## Data Dictionary for Weekly charts
## Data Explanation

### Dataset Details
#### Dataset name: Southeast Asia Countries using Spotify Top Chart Data
#### Year of data: 2019-2021
#### Purpose of dataset 
#### Data dimension -> number of rows and column 
Rows: 355,466
Columns: 15

#### Data content -> description of each column 
  - chart_position: This is the rank of a song for the given chart date
  - chart_date: This is the date of the chart
  - song: This is the name of the song as it shows within Spotify
  - performer: This is the performer(s) of the song
  - song_id: This is a concatenation of the song & performer. Used as a unique id for each song. There is a ONE TO MANY relationship between song_id and spotify_uri. There can be multiple versions of of the same song, e.g. a single versus an album track.
  - streams: This is the count of streams for the song for the date. [Click here for more info about stream count from Spotify](https://artists.spotify.com/help/article/how-we-calculate-charts)
  - spotify_uri: This is the unique Spotify URI for a particular song. A single song can have multiple URIs, such as the song from album vs song from single could have the same song_id but different URIs
  - region: The region or country
  - time_on_chart: This is the cumulative total number of weeks a song (by song_id) has appeared on the chart
  - consecutive_weeks: This is the cumulative consecutive weeks a song (by song_id) has appeared on the chart. If a song skips a week, this column will start counting over
  - previous_week: This is the previous rank for consecutive time. If this column is null, it is either the initial debut or a reappearance on the chart
  - peak_position: This is the cumulative highest/best ranking so far for that song
  - worst_position: This is the cumulative lowest/worst ranking so far for that song
  
#### Data structure -> shows the table sample 
- glimpse(df)
  
  
## Data Preparation
### combine csv and Add a new column "Country" and assign a value based on the country code.

```{r}
au<-read.csv("southeast_dataset/weekly_au_merged.csv")
au<-cbind(au,country="Australia")

id<-read.csv("southeast_dataset/weekly_id_merged.csv")
id<-cbind(id,country="Indonesia")

my<-read.csv("southeast_dataset/weekly_my_merged.csv")
my<-cbind(my,country="Malaysia")

ph<-read.csv("southeast_dataset/weekly_ph_merged.csv")
ph<-cbind(ph,country="Philippines")

sg<-read.csv("southeast_dataset/weekly_sg_merged.csv")
sg<-cbind(sg,country="Singapore")

th<-read.csv("southeast_dataset/weekly_th_merged.csv")
th<-cbind(th,country="Thailand")

vn<-read.csv("southeast_dataset/weekly_vn_merged.csv")
vn<-cbind(vn,country="Viet Nam")

df<-rbind(au,id,my,ph,sg,th,vn)

dim(df)
head(df)
tail(df)
str(df)
```


### Data Cleaning
```{r }
table(is.na(df))
```
**can see that there are missing data**

**check the data and cleaning**

```{r}
# row
nrow(df)
```
```{r}
#check which column has null value
cname<-names(df)
for(i in cname){
  print(paste(i, sum(is.na(df[i]))))
}
```

**no need to delete null values, because
**consecutive_weeks: This is the cumulative consecutive weeks a song (by song_id) has appeared on the chart. If a song skips a week, this column will start counting over
**previous_week: This is the previous rank for consecutive time. If this column is null, it is either the initial debut or a reappearance on the chart

#### Replace null values with 0.
```{r}
df_new<-df
for(i in cname){
  df_new[is.na(df_new[i]),]<-0
}
```

```{r}
table(is.na(df_new))

# check rows
nrow(df_new)
nrow(df)
```

#### Get and get songs with the first ranking position
- chart_position: This is the rank of a song for the given chart date

```{r}
df_new1 <- df_new[df_new$chart_position == 1, ]
head(df_new1)
```
### Extract data by year - delete some rows
- 2017-2021
#### Collating date type data
```{r year}
library(lubridate)
shijian<-ymd(df_new1$chart_date)
df_new2 <- df_new1
df_new2$year <- year(shijian)
df_new2$month <- month(shijian)

df_new1 <- filter(df_new2, year!=2022, year!=2016)
```
## Data Exploration - EDA

-Data Overview: 2017-2021 Southeast Asia song traffic ranking by country, hot song ranking, artist ranking
-By year: yearly song traffic change, yearly artist hotness, song hotness

### Sorting countries by hotness
```{r}
song1<-aggregate(streams~country,df_new1,max)
aves1<-song1[order(song1$streams,decreasing = TRUE),]
aves1

```

### Visualization
#### Southeast Asian Countries Music Hotness Ranking
```{r}
library(ggplot2)
ggplot(aves1[1:10,],aes(x=country,y=streams,group=1)) +geom_point()+coord_flip()+geom_line()+geom_text(aes(label=country,hjust=0.3))

```
```{r}
library(ggplot2)
ggplot(data = aves1, aes(x = reorder(country,streams), y = streams)) + geom_bar(stat = 'identity') + xlab('Southeast Asia countries')+ geom_bar(stat='identity')+coord_flip()+labs(title = "2017-2021Year Southeast Asia streams ranking")

```


#### Top music for sorting hotness - hot song ranking
- (wordcloud)

```{r}
library(dplyr)
top<-df_new1[order(df_new1$streams,decreasing = TRUE),]
top_song <- select(top[1:30,],"song","streams")
top_song
```

```{r}
library(wordcloud2)
wordcloud2(top_song, 
           size = 0.4,                  
           fontFamily = 'Segoe UI',   
           fontWeight = 'bold',       
           color = 'random-dark',     
           backgroundColor = "white", #
           minRotation = -pi/4,       # minRotation and maxRotation countrol words rotation
           maxRotation = pi/4,
           rotateRatio = 0.4,         # almost 40% words rotation
           shape = "circle"           
          )
```
#### Most Popular Singers 2017-2021
#### performers-streams
```{r}
pf<-aggregate(streams~year+performer, df_new2, sum)
pf1<-pf[order(sg$streams,decreasing = TRUE),]
```

```{r}
pf3=pf1 %>% group_by(performer) %>% top_n(n=5,wt=streams)
pf3 <- pf3[order(pf3$streams,decreasing = TRUE),]
pf3
```

```{r}
pf2=pf1 %>% group_by(year) %>% top_n(n=5,wt=streams)
pf2 <- pf2[order(pf2$year,decreasing = TRUE),]

wc_pf <- pf2[,-c(1)]
```

```{r}
library(wordcloud2)
wordcloud2(wc_pf, 
           size = 0.4,                  
           fontFamily = 'Segoe UI',   
           fontWeight = 'bold',       
           color = 'random-dark',     
           backgroundColor = "white", #
           minRotation = -pi/4,       # minRotation and maxRotation countrol words rotation
           maxRotation = pi/4,
           rotateRatio = 0.4,         # almost 40% words rotation
           shape = "circle"           
          )
```

#### Yearly trend of song popularity
```{r}
ys<-aggregate(streams~year+month,df_new2,sum)
ys<-ys[order(ys$year,decreasing = TRUE),]
ys
```

```{r}
ggplot(ys, aes(month, streams,color=year))+
  geom_point(size=4)+
  geom_line(position = position_dodge(0.1),cex=1.3)+labs(title = "Yearly trend of song popularity")
```
### By year: yearly song traffic change
```{r}
sg<-aggregate(streams~year+song,df_new2,sum)
sg1<-sg[order(sg$streams,decreasing = TRUE),]
```
#### Top 5 song streams per year
```{r}
#top_n
r2=sg1 %>% group_by(year) %>% top_n(n=5,wt=streams)
r3 <- r2[order(r2$year,decreasing = TRUE),]
r3
```

```{r}
library(ggplot2)
ggplot(r2,aes(x = song,y = streams))+
  geom_bar(stat = 'identity',aes(fill = year))+
  theme(text=element_text(family="Songti SC",size=12,face = "bold"),axis.text.x = element_text(size=10,angle = 45))

```

#### Top 5 performer per year
```{r}
#top_n
pf2=pf1 %>% group_by(year) %>% top_n(n=5,wt=streams)
pf2 <- pf2[order(pf2$year,decreasing = TRUE),]
pf2
```


```{r}
library(ggplot2)
ggplot(pf2,aes(x = performer,y = streams))+
  geom_bar(stat = 'identity',aes(fill = year))+
  theme(text=element_text(family="Songti SC",size=12,face = "bold"),axis.text.x = element_text(size=10,angle = 45))

```
```{r}
yp<-aggregate(streams~year+Month+performer,df_new2,sum)
yp<-yp[order(yp$year,decreasing = TRUE),]
yp

```


```{r}
library(dplyr)
###preprocess
df_new1$year <- as.numeric(df_new1$year)

df_feature<- df_new1 %>%
  select(performer, chart_position, streams, consecutive_weeks) %>%
  filter(df_new1$year<=2021,df_new1$year>=2019)

Total_stream <- aggregate(df_feature$streams,list(df_feature$performer),sum)
No1_frequence <- aggregate(df_feature$chart_position,list(df_feature$performer),sum)
Max_consecutive_week <- aggregate(df_feature$consecutive_weeks,list(df_feature$performer),max)


df_feature_train<-data.frame(Total_stream)
df_feature_train$No1_frequence<-No1_frequence[,2]
df_feature_train$Max_consecutive_week<-Max_consecutive_week[,2]
colnames(df_feature_train) <- c("Performer","Total_stream","No1_frequence","Max_consecutive_week")

#feature scaled
df_feature_train_scaled<-df_feature_train
df_feature_train_scaled[c("Total_stream","No1_frequence","Max_consecutive_week")] <- scale(df_feature_train[c("Total_stream","No1_frequence","Max_consecutive_week")])

df_train <- df_feature_train_scaled[,2:4]
row.names(df_train)<-df_feature_train_scaled$Performer

write.csv(df_train,"df_train.csv")

install.packages("ClusterR")
install.packages("cluster")
install.packages("factoextra")
library(factoextra)
library(ClusterR)
library(cluster)

#find number of clusters based on SSE
fviz_nbclust(df_train, kmeans, method = "wss")

#find number of clusters based on gap statistic
gap_stat <- clusGap(df_train,
                    FUN = kmeans,
                    nstart = 25,
                    K.max = 10,
                    B = 50)
#plot number of clusters vs. gap statistic
fviz_gap_stat(gap_stat)

#we found that 10 will be the suitable cluster number.


# set the random seed for Result reproduction
set.seed(1)

# Use kMeans k = 10
km <- kmeans(df_train, centers = 10, nstart = 25)

# check the finals
km

#scatter plot by fviz_cluster()
fviz_cluster(km, data = df_train)

#The popular performer in Southeast-Asia from 2019-2021
Popular_Performer <- km$cluster[km$cluster == 1]
Popular_Performer
```





